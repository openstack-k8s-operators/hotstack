---
stages:
  - name: TopoLVM common
    documentation: |
      Install the TopoLVM Container Storage Interface (CSI) driver on the OCP
      cluster.

      It uses LVMS (Logical Volume Manager Storage) to dynamically provision
      local storage built from block devices on OCP nodes.

      After you have installed LVM Storage, you must create an LVMCluster custom resource (CR).
    manifest: ../common/topolvm.yaml
    wait_conditions:
      - "oc wait namespaces openshift-storage --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - >-
        oc wait -n openshift-storage operatorgroups.operators.coreos.com openshift-storage-operatorgroup
        --for jsonpath='{.status.namespaces}' --timeout=30s
      - >-
        oc wait -n openshift-storage ClusterServiceVersion 
        -l operators.coreos.com/lvms-operator.openshift-storage 
        --for jsonpath='{.status.phase}=Succeeded' --timeout=300s
  
  - name: TopoLVM LVMCluster
    documentation: |
      Create a TopoLVM - LVMCluster on the Openshift cluster.

      Configure the LVMCluster custom resource (CR) to perform the following
      actions:

      * Create LVM volume groups that you can use to provision persistent
        volume claims (PVCs).
      * Configure a list of devices that you want to add to the LVM volume
        groups.
    manifest: ../common/topolvmcluster.yaml
    wait_conditions:
      - "oc wait -n openshift-storage lvmcluster.lvm.topolvm.io/lvmcluster --for jsonpath='{.status.state}=Ready' --timeout=300s"

  - name: Node label cinder-lvm
    documentation: |
      The LVM backend for Cinder is a special case as the storage data is on
      the OpenShift node and has no external storage systems. This has several
      implications.
      
      * To prevent issues with exported volumes, cinder-operator automatically
        uses the host network. The backend is configured to use the host's
        VLAN IP address. This means that the cinder-volume service doesn't
        need any networkAttachments.
      * There can only be one node with the label openstack.org/cinder-lvm=.
        Apply the label using the command: ``oc label node <nodename> openstack.org/cinder-lvm=``
    cmd: "oc label node master-0 openstack.org/cinder-lvm="

  - name: Metal platform Provisioning CR
    documentation: |
      Create a Provisioning custom resource (CR) to enable OCP Metal platform components
    manifest: ../common/provisioning.yaml
    wait_conditions:
      - "sleep 30"
      - "oc wait pods -n openshift-machine-api -l k8s-app=metal3 --for condition=Ready --timeout=300s"

  - name: Common OLM
    documentation: |
      Install the OpenStack K8S operators and their dependencies. (Namespaces, 
      OperatorGroup, and Subscription CRs.)

      Once these CRs are created, run the `oc wait` commands to confirm that
      each step of this procedure is complete.
    j2_manifest: ../common/olm.yaml.j2
    wait_conditions:
      - "oc wait namespaces cert-manager-operator --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces metallb-system --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openshift-nmstate --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openstack-operators --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openstack --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait -n cert-manager-operator pod --for condition=Ready -l name=cert-manager-operator --timeout=300s"
      - "oc wait -n cert-manager pod -l app=cainjector --for condition=Ready --timeout=300s"
      - "oc wait -n cert-manager pod -l app=webhook --for condition=Ready --timeout=300s"
      - "oc wait -n cert-manager pod -l app=cert-manager --for condition=Ready --timeout=300s"
      - "oc wait -n metallb-system pod -l control-plane=controller-manager --for condition=Ready --timeout=300s"
      - "oc wait -n metallb-system pod -l component=webhook-server --for condition=Ready --timeout=300s"
      - "oc wait -n openshift-nmstate deployments/nmstate-operator --for condition=Available --timeout=300s"

  - name: Common MetalLB
    manifest: ../common/metallb.yaml
    wait_conditions:
      - "oc wait -n metallb-system pod -l component=speaker --for condition=Ready --timeout=300s"
  
  - name: Common NMState
    manifest: ../common/nmstate.yaml
    wait_conditions:
      - "oc wait -n openshift-nmstate pod -l component=kubernetes-nmstate-handler --for condition=Ready --timeout=300s"
      - "oc wait -n openshift-nmstate deployments/nmstate-webhook --for condition=Available --timeout=300s"

  - name: Openstack
    manifest: ../common/openstack.yaml
    wait_conditions:
      - "oc wait -n openstack-operators openstack openstack --for condition=Ready --timeout=300s"
      - "oc wait -n openstack-operators pod --for condition=Ready -l openstack.org/operator-name=openstack-controller --timeout=300s"
      - "oc wait -n openstack-operators -l openstack.org/operator-name deployment --for condition=Available --timeout=300s"
      - "oc wait -n openstack-operators -l app.kubernetes.io/name=rabbitmq-cluster-operator deployment --for condition=Available --timeout=300s"
      - "oc wait -n openstack-operators service infra-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "oc wait -n openstack-operators service openstack-baremetal-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "oc wait -n openstack-operators service openstack-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "sleep 120" # The {.status.loadBalancer} wait conditions are not working?

  - name: Namespaces
    manifest: ./manifests/namespaces.yaml
    wait_conditions:
      - oc wait namespaces openstack-a --for jsonpath='{.status.phase}=Active' --timeout=1m
      - oc wait namespaces openstack-b --for jsonpath='{.status.phase}=Active' --timeout=1m

  - name: Shared NNCP
    manifest: ./manifests/shared_nncp.yaml
    wait_conditions:
      - >-
        oc wait -n openstack nncp master-0-shared
        --for jsonpath='{.status.conditions[0].reason}'=SuccessfullyConfigured
        --timeout=5m

  - name: NodeNetworkConfigurationPolicy (nncp)
    manifest: manifests/networking/nncp.yaml
    wait_conditions:
      - >-
        oc wait -n openstack-a nncp master-0-a
        --for jsonpath='{.status.conditions[0].reason}'=SuccessfullyConfigured
        --timeout=5m
      - >-
        oc wait -n openstack-b nncp master-0-b
        --for jsonpath='{.status.conditions[0].reason}'=SuccessfullyConfigured
        --timeout=5m

  - name: NetworkAttchmentDefinition (NAD)
    manifest: manifests/networking/nad.yaml

  - name: MetalLB - L2Advertisement and IPAddressPool
    manifest: manifests/networking/metallb.yaml

  - name: Netcofnig
    manifest: manifests/networking/netconfig.yaml

  - name: OpenstackControlPlane secrets
    manifest: manifests/control-planes/secrets.yaml

  - name: OpenstackControlPlane
    manifest: manifests/control-planes/control-planes.yaml
    wait_conditions:
      - >-
        oc wait -n openstack-a openstackcontrolplane controlplane
        --for condition=Ready --timeout=60m
      - >-
        oc wait -n openstack-b openstackcontrolplane controlplane
        --for condition=Ready --timeout=60m

  - name: Cloud a - Dataplane SSH key secret
    cmd: >-
      oc create -n openstack-a secret generic dataplane-ansible-ssh-private-key-secret
      --save-config --dry-run=client
      --from-file=authorized_keys=/home/zuul/.ssh/id_rsa.pub
      --from-file=ssh-privatekey=/home/zuul/.ssh/id_rsa
      --from-file=ssh-publickey=/home/zuul/.ssh/id_rsa.pub
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >- 
        oc wait -n openstack-a secret dataplane-ansible-ssh-private-key-secret
        --for jsonpath='{.metadata.name}= dataplane-ansible-ssh-private-key-secret'
        --timeout=30s

  - Name: Cloud b - Dataplane SSH key secret
    cmd: >-
      oc create -n openstack-b secret generic dataplane-ansible-ssh-private-key-secret
      --save-config --dry-run=client
      --from-file=authorized_keys=/home/zuul/.ssh/id_rsa.pub
      --from-file=ssh-privatekey=/home/zuul/.ssh/id_rsa
      --from-file=ssh-publickey=/home/zuul/.ssh/id_rsa.pub
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >- 
        oc wait -n openstack-b secret dataplane-ansible-ssh-private-key-secret
        --for jsonpath='{.metadata.name}= dataplane-ansible-ssh-private-key-secret'
        --timeout=30s

  - name: Cloud a - Nova migration SSH key secret
    cmd: >-
      oc create -n openstack-a secret generic nova-migration-ssh-key
      --save-config --dry-run=client
      --from-file=ssh-privatekey=/home/zuul/.ssh/id_nova_migrate
      --from-file=ssh-publickey=/home/zuul/.ssh/id_nova_migrate.pub
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >-
        oc wait -n openstack-a secret nova-migration-ssh-key
        --for jsonpath='{.metadata.name}=nova-migration-ssh-key'
        --timeout=30s

  - Name: Cloud b - Nova migration SSH key secret
    cmd: >-
      oc create -n openstack-b secret generic nova-migration-ssh-key
      --save-config --dry-run=client
      --from-file=ssh-privatekey=/home/zuul/.ssh/id_nova_migrate
      --from-file=ssh-publickey=/home/zuul/.ssh/id_nova_migrate.pub
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >-
        oc wait -n openstack-b secret nova-migration-ssh-key
        --for jsonpath='{.metadata.name}=nova-migration-ssh-key'
        --timeout=30s

  - name: Dataplane Secrets
    manifest: manifests/dataplanes/secrets.yaml

  - name: Cloud a - BaremetalHosts BMC secret
    cmd: >-
      oc create -n openstack-a secret generic bmc-secret
      --save-config --dry-run=client
      --from-literal=username=admin
      --from-literal=password=password
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >-
        oc wait -n openstack-a secret bmc-secret
        --for jsonpath='{.metadata.name}=bmc-secret'
        --timeout=30s

  - Name: Cloud b - BaremetalHosts BMC secret
    cmd: >-
      oc create -n openstack-b secret generic bmc-secret
      --save-config --dry-run=client
      --from-literal=username=admin
      --from-literal=password=password
      --type=Opaque -o yaml | oc apply -f -
    wait_conditions:
      - >-
        oc wait -n openstack-b secret bmc-secret
        --for jsonpath='{.metadata.name}=bmc-secret'
        --timeout=30s

  - name: BaremetalHosts CRs
    j2_manifest: manifests/dataplanes/baremetal_hosts.yaml.j2
    wait_conditions:
      - sleep 20
      - >-
        oc wait -n openstack-a baremetalhosts.metal3.io bmh-a-0
        --for jsonpath='{.status.provisioning.state}=available'
        --timeout=300s
      - >-
        oc wait -n openstack-b baremetalhosts.metal3.io bmh-b-0
        --for jsonpath='{.status.provisioning.state}=available'
        --timeout=300s

  - name: OpenStackProvisionServer resources
    manifest: manifests/dataplanes/provisioningservers.yaml
    wait_conditions:
      - >-
        oc wait -n openstack-a openstackprovisionservers.baremetal.openstack.org
        openstack-a-edpm-provisionserver --for condition=Ready --timeout=10m
      - >-
        oc wait -n openstack-b openstackprovisionservers.baremetal.openstack.org
        openstack-b-edpm-provisionserver --for condition=Ready --timeout=10m

  - name: Dataplane nodeset
    manifest: manifests/dataplanes/nodesets.yaml
    wait_conditions:
      - >-
        oc wait -n openstack-a openstackdataplanenodesets.dataplane.openstack.org
        openstack-edpm --for condition=SetupReady --timeout=10m
      - >-
        oc wait -n openstack-b openstackdataplanenodesets.dataplane.openstack.org
        openstack-edpm --for condition=SetupReady --timeout=10m

  - name: Dataplane Deployment
    manifest: manifests/dataplanes/deployments.yaml
    wait_conditions:
      - >-
        oc wait -n openstack-a openstackdataplanedeployments.dataplane.openstack.org
        dataplane --for condition=Ready --timeout=40m
      - >-
        oc wait -n openstack-b openstackdataplanedeployments.dataplane.openstack.org
        dataplane --for condition=Ready --timeout=40m
