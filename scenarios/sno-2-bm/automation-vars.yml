---
stages:
  - name: TopoLVM common
    documentation: |
      Install the TopoLVM Container Storage Interface (CSI) driver on the OCP
      cluster.

      It uses LVMS (Logical Volume Manager Storage) to dynamically provision
      local storage built from block devices on OCP nodes.

      After you have installed LVM Storage, you must create an LVMCluster custom resource (CR).
    manifest: ../common/topolvm.yaml
    wait_conditions:
      - "oc wait namespaces openshift-storage --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - >-
        oc wait -n openshift-storage operatorgroups.operators.coreos.com openshift-storage-operatorgroup
        --for jsonpath='{.status.namespaces}' --timeout=30s
      - >-
        oc wait -n openshift-storage ClusterServiceVersion
        -l operators.coreos.com/lvms-operator.openshift-storage
        --for jsonpath='{.status.phase}=Succeeded' --timeout=300s

  - name: TopoLVM LVMCluster
    documentation: |
      Create a TopoLVM - LVMCluster on the Openshift cluster.

      Configure the LVMCluster custom resource (CR) to perform the following
      actions:

      * Create LVM volume groups that you can use to provision persistent
        volume claims (PVCs).
      * Configure a list of devices that you want to add to the LVM volume
        groups.
    manifest: ../common/topolvmcluster.yaml
    wait_conditions:
      - "oc wait -n openshift-storage lvmcluster.lvm.topolvm.io/lvmcluster --for jsonpath='{.status.state}=Ready' --timeout=300s"

  - name: Node label cinder-lvm
    documentation: |
      The LVM backend for Cinder is a special case as the storage data is on
      the OpenShift node and has no external storage systems. This has several
      implications.

      * To prevent issues with exported volumes, cinder-operator automatically
        uses the host network. The backend is configured to use the host's
        VLAN IP address. This means that the cinder-volume service doesn't
        need any networkAttachments.
      * There can only be one node with the label openstack.org/cinder-lvm=.
        Apply the label using the command: ``oc label node <nodename> openstack.org/cinder-lvm=``
    cmd: "oc label node master-0 openstack.org/cinder-lvm="

  - name: Common OLM
    documentation: |
      Install the OpenStack K8S operators and their dependencies. (Namespaces,
      OperatorGroup, and Subscription CRs.)

      Once these CRs are created, run the `oc wait` commands to confirm that
      each step of this procedure is complete.
    j2_manifest: ../common/olm.yaml.j2
    wait_conditions:
      - "oc wait namespaces cert-manager-operator --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces metallb-system --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openshift-nmstate --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openstack-operators --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait namespaces openstack --for jsonpath='{.status.phase}=Active' --timeout=300s"
      - "oc wait -n cert-manager-operator pod --for condition=Ready -l name=cert-manager-operator --timeout=300s"
      - "oc wait -n cert-manager pod -l app=cainjector --for condition=Ready --timeout=300s"
      - "oc wait -n cert-manager pod -l app=webhook --for condition=Ready --timeout=300s"
      - "oc wait -n cert-manager pod -l app=cert-manager --for condition=Ready --timeout=300s"
      - "oc wait -n metallb-system pod -l control-plane=controller-manager --for condition=Ready --timeout=300s"
      - "oc wait -n metallb-system pod -l component=webhook-server --for condition=Ready --timeout=300s"
      - "oc wait -n openshift-nmstate deployments/nmstate-operator --for condition=Available --timeout=300s"

  - name: Common MetalLB
    manifest: ../common/metallb.yaml
    wait_conditions:
      - "oc wait -n metallb-system pod -l component=speaker --for condition=Ready --timeout=300s"

  - name: Common NMState
    manifest: ../common/nmstate.yaml
    wait_conditions:
      - "oc wait -n openshift-nmstate pod -l component=kubernetes-nmstate-handler --for condition=Ready --timeout=300s"
      - "oc wait -n openshift-nmstate deployments/nmstate-webhook --for condition=Available --timeout=300s"

  - name: Openstack
    manifest: ../common/openstack.yaml
    wait_conditions:
      - "oc wait -n openstack-operators openstack openstack --for condition=Ready --timeout=300s"
      - "oc wait -n openstack-operators pod --for condition=Ready -l openstack.org/operator-name=openstack-controller --timeout=300s"
      - "oc wait -n openstack-operators -l openstack.org/operator-name deployment --for condition=Available --timeout=300s"
      - "oc wait -n openstack-operators -l app.kubernetes.io/name=rabbitmq-cluster-operator deployment --for condition=Available --timeout=300s"
      - "oc wait -n openstack-operators service infra-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "oc wait -n openstack-operators service openstack-baremetal-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "oc wait -n openstack-operators service openstack-operator-webhook-service --for jsonpath='{.status.loadBalancer}' --timeout=300s"
      - "sleep 30"  # The {.status.loadBalancer} wait conditions are not working?

  - name: Patch openstack leader election tuneables
    script: |
      LEASE_DURATION_INDEX=$(oc -n openstack-operators get csv/openstack-operator.v0.3.0 -o json | \
        jq '.spec.install.spec.deployments[0].spec.template.spec.containers[0].env |
            map(.name == "LEASE_DURATION") |
            index(true)')
      RENEW_DEADLINE_INDEX=$(oc -n openstack-operators get csv/openstack-operator.v0.3.0 -o json | \
        jq '.spec.install.spec.deployments[0].spec.template.spec.containers[0].env |
            map(.name == "RENEW_DEADLINE") |
            index(true)')
      RETRY_PERIOD_INDEX=$(oc -n openstack-operators get csv/openstack-operator.v0.3.0 -o json | \
        jq '.spec.install.spec.deployments[0].spec.template.spec.containers[0].env |
            map(.name == "RETRY_PERIOD") |
            index(true)')

      oc -n openstack-operators patch csv/openstack-operator.v0.3.0 --type=json \
        -p="[
              {'op': 'replace',
              'path': '/spec/install/spec/deployments/0/spec/template/spec/containers/0/env/$LEASE_DURATION_INDEX/value',
              'value': '50'},
              {'op': 'replace',
              'path': '/spec/install/spec/deployments/0/spec/template/spec/containers/0/env/$RENEW_DEADLINE_INDEX/value',
              'value': '30'},
              {'op': 'replace',
              'path': '/spec/install/spec/deployments/0/spec/template/spec/containers/0/env/$RETRY_PERIOD_INDEX/value',
              'value': '10'}
            ]"
    wait_conditions:
      - sleep 10
      - >-
        oc wait -n openstack-operators leases.coordination.k8s.io c569355b.openstack.org
        --for jsonpath='{.spec.leaseDurationSeconds}'=50
        --timeout=2m
      - "oc wait -n openstack-operators openstack openstack --for condition=Ready --timeout=5m"

  - name: NodeNetworkConfigurationPolicy (nncp)
    manifest: manifests/control-plane/networking/nncp.yaml
    wait_conditions:
      - >-
        oc wait -n openstack nncp -l osp/nncm-config-type=standard
        --for jsonpath='{.status.conditions[0].reason}'=SuccessfullyConfigured
        --timeout=5m

  - name: NetworkAttchmentDefinition (NAD)
    manifest: manifests/control-plane/networking/nad.yaml

  - name: MetalLB - L2Advertisement and IPAddressPool
    manifest: manifests/control-plane/networking/metallb.yaml

  - name: Netconfig
    manifest: manifests/control-plane/networking/netconfig.yaml

  - name: OpenstackControlPlane
    manifest: manifests/control-plane/control-plane.yaml
    wait_conditions:
      - >-
        oc wait -n openstack openstackcontrolplane controlplane
        --for condition=Ready --timeout=60m
